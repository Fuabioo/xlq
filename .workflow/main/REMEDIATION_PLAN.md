# REMEDIATION_PLAN.md

**Generated By**: Planner Agent
**Generated At**: 2026-01-23
**Project Type**: Backend CLI Tool (Go)
**Status**: Ready for Development

## 1. Executive Summary

This plan addresses 7 empirically validated issues in the xlq project, prioritized by severity. The issues range from CRITICAL goroutine leaks and memory violations to HIGH-severity security vulnerabilities and race conditions. Each fix is designed to be atomic and independently verifiable using existing proof tests.

**Total Estimated Effort**: 21 story points (~10-11 days)

## 2. Issue Inventory

| ID | Issue | Severity | Est. | Test File |
|----|-------|----------|------|-----------|
| G1 | Goroutine leaks in StreamRows | CRITICAL | 3 pts | `internal/xlsx/goroutine_leak_test.go` |
| G2 | Goroutine leaks in StreamRange | CRITICAL | 2 pts | `internal/xlsx/goroutine_leak_test.go` |
| G3 | Goroutine leaks in Search | CRITICAL | 2 pts | `internal/xlsx/goroutine_leak_test.go` (needs extension) |
| M1 | StreamTail memory violation | CRITICAL | 5 pts | `internal/xlsx/memory_bench_test.go` |
| S1 | Path traversal vulnerability | HIGH | 3 pts | `internal/mcp/security_test.go` |
| R1 | CLI race conditions | HIGH | 2 pts | `internal/cli/race_test.go` |
| C1 | MCP context ignored | HIGH | 2 pts | New: `internal/mcp/context_test.go` |
| L1 | LRU cache dead code | HIGH | 1 pt | `internal/cache/lru_test.go` |
| U1 | CLI read unbounded | HIGH | 1 pt | New: `internal/cli/read_test.go` |

## 3. Dependency Graph

```
     G1 (StreamRows goroutine leak)
         |
    +----+----+
    |         |
   G2        G3
(StreamRange)(Search)
    |
   M1 (StreamTail memory - depends on understanding streaming pattern)

Independent:
  S1 (Path traversal)
  R1 (CLI races)
  C1 (MCP context)
  L1 (LRU decision)
  U1 (CLI read limit)
```

**Recommended execution order**:
1. Phase 1 (Critical): G1 -> G2, G3 (parallel) -> M1
2. Phase 2 (High): S1, R1, C1, L1, U1 (all independent, can be parallel)

---

## 4. Implementation Tasks

### Phase 1: CRITICAL Fixes (12 pts, ~6 days)

---

### Task G1: Fix Goroutine Leak in StreamRows

**Severity**: CRITICAL
**Estimate**: 3 story points (~1.5 days)
**Dependencies**: None (this is the foundation)

#### Problem Analysis

The `StreamRows` function at `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go:18-75` spawns a goroutine that writes to an unbuffered channel. When the receiver abandons the channel (stops reading early), the goroutine blocks forever on `ch <- RowResult{...}` at line 66.

**Root cause**: Unbuffered channel with no cancellation mechanism.

```go
// Current code (lines 29-72)
ch := make(chan RowResult)  // UNBUFFERED

go func() {
    defer close(ch)
    defer rows.Close()
    // ...
    ch <- RowResult{Row: &Row{...}}  // BLOCKS FOREVER if no receiver
}()
```

#### Solution: Context-based Cancellation

Add a `context.Context` parameter to enable cancellation. Use `select` to check for cancellation on each send.

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go`**

   Change function signature:
   ```go
   // BEFORE
   func StreamRows(f *excelize.File, sheet string, startRow, endRow int) (<-chan RowResult, error)

   // AFTER
   func StreamRows(ctx context.Context, f *excelize.File, sheet string, startRow, endRow int) (<-chan RowResult, error)
   ```

   Add select with context check:
   ```go
   ch := make(chan RowResult)

   go func() {
       defer close(ch)
       defer rows.Close()

       rowNum := 0
       for rows.Next() {
           rowNum++
           // ... existing row processing ...

           select {
           case <-ctx.Done():
               return  // Receiver cancelled, exit gracefully
           case ch <- RowResult{Row: &Row{Number: rowNum, Cells: cells}}:
               // Successfully sent
           }
       }
       // Handle final error
       if err := rows.Error(); err != nil {
           select {
           case <-ctx.Done():
               return
           case ch <- RowResult{Err: fmt.Errorf("row iteration error: %w", err)}:
           }
       }
   }()
   ```

2. **Update all callers** (propagate context):
   - `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go` - `StreamHead`, `StreamRowsToStrings`
   - `/home/fuabioo/Playground/excelize-mcp/internal/cli/read.go`
   - `/home/fuabioo/Playground/excelize-mcp/internal/cli/head.go`
   - `/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go` - handlers

#### Test File

**Existing**: `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/goroutine_leak_test.go`

#### Acceptance Criteria

1. `TestGoroutineLeakStreamRows` PASSES (leaked goroutines < 2 after abandoning 10 channels)
2. `TestGoroutineNoLeakFullConsumption` continues to PASS
3. `TestGoroutineLeakTiming` shows goroutine exits within 100ms after context cancellation

#### New Test to Add

```go
// TestStreamRowsContextCancellation verifies goroutines exit when context is cancelled
func TestStreamRowsContextCancellation(t *testing.T) {
    path := createLargeTestFile(t, 1000)
    f, err := OpenFile(path)
    if err != nil {
        t.Fatalf("OpenFile failed: %v", err)
    }
    defer f.Close()

    ctx, cancel := context.WithCancel(context.Background())

    ch, err := StreamRows(ctx, f, "Sheet1", 1, 1000)
    if err != nil {
        t.Fatalf("StreamRows failed: %v", err)
    }

    // Read one row
    <-ch

    // Record goroutine count
    baseline := runtime.NumGoroutine()

    // Cancel context
    cancel()

    // Wait for goroutine to exit
    time.Sleep(100 * time.Millisecond)
    runtime.GC()

    after := runtime.NumGoroutine()
    if after >= baseline {
        t.Errorf("Goroutine did not exit after cancel: before=%d, after=%d", baseline, after)
    }
}
```

---

### Task G2: Fix Goroutine Leak in StreamRange

**Severity**: CRITICAL
**Estimate**: 2 story points (~1 day)
**Dependencies**: G1 (same pattern, apply after G1 is validated)

#### Problem Analysis

Same issue as G1 at `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go:78-145`.

#### Solution

Apply identical pattern from G1:
1. Add `ctx context.Context` parameter
2. Use `select` with `ctx.Done()` for all channel sends

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go`** - `StreamRange` function
2. **Update callers**:
   - `/home/fuabioo/Playground/excelize-mcp/internal/cli/read.go`
   - `/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go` - `handleRead`

#### Test File

**Existing**: `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/goroutine_leak_test.go`

#### Acceptance Criteria

1. `TestGoroutineLeakStreamRange` PASSES (leaked goroutines < 2)

---

### Task G3: Fix Goroutine Leak in Search

**Severity**: CRITICAL
**Estimate**: 2 story points (~1 day)
**Dependencies**: G1 (same pattern)

#### Problem Analysis

`Search` function at `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/search.go:26-130` has the same unbuffered channel pattern.

```go
// Line 76
ch := make(chan SearchResultStream)  // UNBUFFERED
```

#### Solution

Add context parameter and use select pattern for all channel sends in the goroutine.

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/xlsx/search.go`**:
   - Change `Search` signature to include `ctx context.Context`
   - Add select with ctx.Done() for all `ch <- SearchResultStream{...}` sends

2. **Update callers**:
   - `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/search.go` - `SearchSimple`, `SearchInSheet`, `SearchRegex`
   - `/home/fuabioo/Playground/excelize-mcp/internal/cli/search.go`
   - `/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go` - `handleSearch`

#### Test File

**New**: Add test to `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/goroutine_leak_test.go`

```go
func TestGoroutineLeakSearch(t *testing.T) {
    path := createLargeTestFile(t, 1000)
    f, err := OpenFile(path)
    if err != nil {
        t.Fatalf("OpenFile failed: %v", err)
    }
    defer f.Close()

    runtime.GC()
    time.Sleep(100 * time.Millisecond)
    baseline := runtime.NumGoroutine()

    const leakAttempts = 10
    for i := 0; i < leakAttempts; i++ {
        ctx, cancel := context.WithCancel(context.Background())
        ch, err := Search(ctx, f, "test", SearchOptions{})
        if err != nil {
            t.Fatalf("Search failed: %v", err)
        }
        // Read one result then abandon
        <-ch
        cancel()
    }

    runtime.GC()
    time.Sleep(500 * time.Millisecond)
    after := runtime.NumGoroutine()
    leaked := after - baseline

    if leaked >= leakAttempts-2 {
        t.Errorf("LEAK: %d goroutines leaked", leaked)
    }
}
```

#### Acceptance Criteria

1. New `TestGoroutineLeakSearch` PASSES

---

### Task M1: Fix StreamTail Memory Violation

**Severity**: CRITICAL
**Estimate**: 5 story points (~2.5 days)
**Dependencies**: Understanding from G1-G3 (streaming patterns)

#### Problem Analysis

`StreamTail` at `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go:155-230` currently allocates `Cell` structs for EVERY row during iteration, even though only the last N rows are kept. The benchmark shows 789k allocations for 10k rows requesting only 10 rows.

**Root cause**: Lines 188-197 allocate cells for each row:
```go
cells := make([]Cell, len(cols))  // Allocated for EVERY row
for i, val := range cols {
    cells[i] = Cell{...}
}
buffer[bufIdx] = Row{Number: rowNum, Cells: cells}
```

The ring buffer only holds N `Row` structs, but it keeps references to newly allocated `cells` slices which are created for every row.

#### Solution: Reuse Cell Allocations

Pre-allocate a pool of N `Row` structs with their `Cell` slices, then reuse them as the ring buffer rotates.

```go
func StreamTail(f *excelize.File, sheet string, n int) ([]Row, error) {
    if n <= 0 {
        n = 10
    }

    resolvedSheet, err := ResolveSheetName(f, sheet)
    if err != nil {
        return nil, err
    }

    rows, err := f.Rows(resolvedSheet)
    if err != nil {
        return nil, fmt.Errorf("failed to open row iterator: %w", err)
    }
    defer rows.Close()

    // Ring buffer with pre-allocated rows
    // We'll track max columns seen to handle varying row widths
    buffer := make([]Row, n)
    maxCols := 0  // Track max columns for final allocation

    bufIdx := 0
    totalRows := 0
    rowNum := 0

    for rows.Next() {
        rowNum++

        cols, err := rows.Columns()
        if err != nil {
            return nil, fmt.Errorf("error reading row %d: %w", rowNum, err)
        }

        // Track max columns
        if len(cols) > maxCols {
            maxCols = len(cols)
        }

        // Store minimal data - just row number and raw values
        // Defer Cell construction until we know which rows to return
        buffer[bufIdx] = Row{
            Number: rowNum,
            raw:    cols,  // NEW: store raw string slice temporarily
        }
        bufIdx = (bufIdx + 1) % n
        totalRows++
    }

    // ... rest of extraction logic, but NOW construct Cell structs
    // only for the N rows we're returning
}
```

**Alternative simpler approach**: Only allocate when writing to a NEW slot, and let GC reclaim old allocations. The issue is the allocation count, not memory retention.

The cleanest fix: Use a pool of pre-sized `[]Cell` slices:

```go
// Pre-allocate cell slices for ring buffer slots
type tailBuffer struct {
    rows []Row
    cellPools [][]Cell  // One per slot, reused
}
```

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go`** - Rewrite `StreamTail` function

#### Test File

**Existing**: `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/memory_bench_test.go`

#### Acceptance Criteria

1. `BenchmarkStreamTailMemory` shows allocations proportional to N (tail size), not total rows
2. `TestStreamTailAllocationCount` shows ~constant allocations across:
   - Small_20rows_tail10
   - Medium_1000rows_tail10
   - Large_10000rows_tail10

**Target**: `Large_10000rows_tail10` should have allocations within 10x of `Small_20rows_tail10`

3. Memory profile confirms < 100MB for any file size (project claim)

---

### Phase 2: HIGH Severity Fixes (9 pts, ~4-5 days)

---

### Task S1: Fix Path Traversal Vulnerability

**Severity**: HIGH (CVSS 7.5)
**Estimate**: 3 story points (~1.5 days)
**Dependencies**: None

#### Problem Analysis

All 7 MCP handlers accept arbitrary file paths without validation. The test at `/home/fuabioo/Playground/excelize-mcp/internal/mcp/security_test.go` confirms handlers allow:
- Absolute paths outside working directory
- Relative paths with `../` traversal
- Symlink-based traversal

#### Solution: Implement Path Validation

Create a path validation utility and apply it to all handlers.

#### Files to Modify

1. **New file**: `/home/fuabioo/Playground/excelize-mcp/internal/mcp/security.go`

```go
package mcp

import (
    "fmt"
    "os"
    "path/filepath"
    "strings"
)

// AllowedBasePaths contains directories from which files can be read.
// Empty slice means current working directory only.
var AllowedBasePaths []string

// ValidateFilePath ensures the path is safe to access.
// Returns the cleaned absolute path if valid, or an error if not.
func ValidateFilePath(path string) (string, error) {
    if path == "" {
        return "", fmt.Errorf("file path cannot be empty")
    }

    // Resolve to absolute path
    absPath, err := filepath.Abs(path)
    if err != nil {
        return "", fmt.Errorf("invalid path: %w", err)
    }

    // Resolve symlinks
    realPath, err := filepath.EvalSymlinks(absPath)
    if err != nil {
        // File might not exist yet, check parent directory
        if os.IsNotExist(err) {
            // For read operations, file must exist
            return "", fmt.Errorf("file not found: %s", path)
        }
        return "", fmt.Errorf("cannot resolve path: %w", err)
    }

    // Check against allowed base paths
    cwd, err := os.Getwd()
    if err != nil {
        return "", fmt.Errorf("cannot determine working directory: %w", err)
    }

    basePaths := AllowedBasePaths
    if len(basePaths) == 0 {
        basePaths = []string{cwd}
    }

    for _, base := range basePaths {
        absBase, err := filepath.Abs(base)
        if err != nil {
            continue
        }
        if strings.HasPrefix(realPath, absBase+string(os.PathSeparator)) || realPath == absBase {
            return realPath, nil
        }
    }

    return "", fmt.Errorf("access denied: path outside allowed directories")
}
```

2. **`/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go`**

   Add validation call at the start of each handler:

```go
func (s *Server) handleSheets(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    file := request.GetString("file", "")

    // ADDED: Validate path
    validPath, err := ValidateFilePath(file)
    if err != nil {
        return mcp.NewToolResultError(err.Error()), nil
    }

    f, err := xlsx.OpenFile(validPath)
    // ... rest unchanged
}
```

   Apply to all 7 handlers:
   - `handleSheets`
   - `handleInfo`
   - `handleRead`
   - `handleHead`
   - `handleTail`
   - `handleSearch`
   - `handleCell`

#### Test File

**Existing**: `/home/fuabioo/Playground/excelize-mcp/internal/mcp/security_test.go`

#### Acceptance Criteria

1. `TestPathTraversalVulnerability` - All path traversal attempts BLOCKED
2. `TestAllHandlersPathTraversal` - All 7 handlers correctly block out-of-scope files
3. `TestSymbolicLinkPathTraversal` - Symlink traversal BLOCKED
4. New test: Valid paths within working directory ALLOWED

---

### Task R1: Fix CLI Race Conditions

**Severity**: HIGH
**Estimate**: 2 story points (~1 day)
**Dependencies**: None

#### Problem Analysis

Package-level variables `headN`, `tailN`, and `formatFlag` in `/home/fuabioo/Playground/excelize-mcp/internal/cli/` cause races when accessed concurrently. The race detector confirms this in `/home/fuabioo/Playground/excelize-mcp/internal/cli/race_test.go`.

Current problematic code:
```go
// root.go line 11
var formatFlag string

// head.go lines 12-13
var headN int

// tail.go lines 12-13
var tailN int
```

#### Solution: Use Command-Local Variables

Move flag variables to be local to each command's scope, accessed via `cmd.Flags()`.

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/cli/root.go`**

```go
// REMOVE package-level variable
// var formatFlag string

func init() {
    // Keep persistent flag registration, but access differently
    rootCmd.PersistentFlags().StringP("format", "f", "json", "Output format (json, csv, tsv)")
}

// GetFormat reads from command context - REPLACE
func GetFormatFromCmd(cmd *cobra.Command) string {
    format, _ := cmd.Flags().GetString("format")
    return format
}
```

2. **`/home/fuabioo/Playground/excelize-mcp/internal/cli/head.go`**

```go
// REMOVE package-level variable
// var headN int

var headCmd = &cobra.Command{
    Use:   "head <file.xlsx> [sheet]",
    Short: "Show first N rows",
    Args:  cobra.RangeArgs(1, 2),
    RunE: func(cmd *cobra.Command, args []string) error {
        // Get flag value from command
        n, _ := cmd.Flags().GetInt("number")
        // ... use n instead of headN
    },
}

func init() {
    headCmd.Flags().IntP("number", "n", 10, "Number of rows to show")
    rootCmd.AddCommand(headCmd)
}
```

3. **`/home/fuabioo/Playground/excelize-mcp/internal/cli/tail.go`** - Same pattern

4. **Update all commands** that call `GetFormat()` to use `GetFormatFromCmd(cmd)`

#### Test File

**Existing**: `/home/fuabioo/Playground/excelize-mcp/internal/cli/race_test.go`

#### Acceptance Criteria

1. `go test -race ./internal/cli/...` passes with ZERO races detected
2. `TestPackageLevelVariableRace` - Test removed or updated (no more package-level vars)
3. `TestParallelCommandRace` - All parallel executions succeed independently

---

### Task C1: Implement MCP Context Cancellation

**Severity**: HIGH
**Estimate**: 2 story points (~1 day)
**Dependencies**: G1, G2, G3 (must have context-aware streaming first)

#### Problem Analysis

All MCP handlers receive a `ctx context.Context` parameter but never use it. Operations cannot be cancelled, which is especially problematic for long-running searches or large file reads.

Example from `/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go:97`:
```go
func (s *Server) handleSheets(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    // ctx is NEVER used!
```

#### Solution

After G1-G3 are complete, pass ctx to all streaming functions and add cancellation checks.

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go`**

   Update all handlers to pass context:
   ```go
   func (s *Server) handleRead(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
       // ... validation ...
       ch, err := xlsx.StreamRows(ctx, f, resolvedSheet, 0, 0)  // Pass ctx
       // ...
   }
   ```

   Add timeout wrapper for safety:
   ```go
   func (s *Server) handleSearch(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
       // Add timeout if not already set
       if _, hasDeadline := ctx.Deadline(); !hasDeadline {
           var cancel context.CancelFunc
           ctx, cancel = context.WithTimeout(ctx, 30*time.Second)
           defer cancel()
       }
       // ... rest of handler
   }
   ```

#### Test File

**New**: `/home/fuabioo/Playground/excelize-mcp/internal/mcp/context_test.go`

```go
package mcp

import (
    "context"
    "testing"
    "time"
)

func TestHandlerContextCancellation(t *testing.T) {
    srv := New()

    // Create a cancelled context
    ctx, cancel := context.WithCancel(context.Background())
    cancel() // Cancel immediately

    // Create test file (use existing testdata)
    request := createMockRequest("head", map[string]interface{}{
        "file": "../../testdata/large.xlsx",
        "n":    1000,
    })

    start := time.Now()
    result, err := srv.handleHead(ctx, request)
    elapsed := time.Since(start)

    // Should return quickly due to cancellation
    if elapsed > 1*time.Second {
        t.Errorf("Handler did not respect context cancellation, took %v", elapsed)
    }

    // Result should indicate cancellation or error
    if err == nil && result != nil && !result.IsError {
        t.Error("Handler should have failed due to cancelled context")
    }
}

func TestHandlerContextTimeout(t *testing.T) {
    srv := New()

    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)
    defer cancel()

    request := createMockRequest("search", map[string]interface{}{
        "file":    "../../testdata/large.xlsx",
        "pattern": "test",
    })

    result, err := srv.handleSearch(ctx, request)

    // Should timeout
    if err == nil && result != nil && !result.IsError {
        t.Log("Search completed before timeout - may need larger test file")
    }
}
```

#### Acceptance Criteria

1. All handlers pass ctx to underlying operations
2. Operations return promptly when context is cancelled
3. New context tests pass

---

### Task L1: Resolve LRU Cache Dead Code

**Severity**: HIGH (Technical Debt)
**Estimate**: 1 story point (~0.5 day)
**Dependencies**: None

#### Problem Analysis

A complete LRU cache implementation exists at `/home/fuabioo/Playground/excelize-mcp/internal/cache/lru.go` (140 lines) with tests, but it is never used anywhere in the codebase. This is either:
- Dead code that should be deleted
- A planned optimization that was never integrated

#### Decision Required

**Option A: Delete the dead code**
- Remove `/home/fuabioo/Playground/excelize-mcp/internal/cache/lru.go`
- Remove `/home/fuabioo/Playground/excelize-mcp/internal/cache/lru_test.go`
- Remove `/home/fuabioo/Playground/excelize-mcp/internal/cache/` directory

**Option B: Integrate LRU cache** (if performance benefit exists)
- The CLAUDE.md mentions "LRU cache for shared strings (max 10k entries)"
- Shared strings in xlsx files could benefit from caching for repeated access
- Integration point: `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/reader.go`

#### Recommended Decision

**Delete the code** (Option A) unless profiling shows shared string lookups are a bottleneck. The current implementation does not use it, and premature optimization adds maintenance burden.

#### Files to Modify

If deleting:
```bash
rm -rf /home/fuabioo/Playground/excelize-mcp/internal/cache/
```

Update imports in any file that might reference it (search shows none currently do).

#### Acceptance Criteria

1. Either: Directory deleted and `go build ./...` succeeds
2. Or: LRU integrated with benchmarks showing measurable improvement

---

### Task U1: Add Default Limit to CLI Read Command

**Severity**: HIGH (Consistency)
**Estimate**: 1 story point (~0.5 day)
**Dependencies**: None

#### Problem Analysis

The MCP `read` handler has a default 1000-row limit (via `DefaultRowLimit` in limits.go), but the CLI `read` command at `/home/fuabioo/Playground/excelize-mcp/internal/cli/read.go` reads ALL rows with no limit:

```go
// CLI read.go lines 57-63 - NO LIMIT
ch, err := xlsx.StreamRows(f, sheet, 0, 0)
// ...
rows, err = xlsx.CollectRows(ch)  // Collects ALL rows
```

This inconsistency means CLI users can accidentally load huge files into memory.

#### Solution

Add a `--limit` flag to the CLI read command with the same defaults as MCP.

#### Files to Modify

1. **`/home/fuabioo/Playground/excelize-mcp/internal/cli/read.go`**

```go
var (
    readLimit int
)

var readCmd = &cobra.Command{
    Use:   "read <file.xlsx> [sheet] [range]",
    Short: "Read cell range",
    Long:  `Read cells from a range (e.g., A1:C10). If no range specified, reads entire sheet (default limit: 1000 rows).`,
    Args:  cobra.RangeArgs(1, 3),
    RunE: func(cmd *cobra.Command, args []string) error {
        // ... existing validation ...

        var rows []xlsx.Row
        if rangeStr != "" {
            // Specific range - no limit needed
            ch, err := xlsx.StreamRange(f, sheet, rangeStr)
            // ...
        } else {
            // Full sheet - apply limit
            ch, err := xlsx.StreamRows(f, sheet, 0, 0)
            if err != nil {
                return err
            }

            limit, _ := cmd.Flags().GetInt("limit")
            if limit <= 0 {
                limit = 1000  // Default
            }

            rows, _, truncated, err := xlsx.CollectRowsWithLimit(ch, limit)
            if err != nil {
                return err
            }

            if truncated {
                fmt.Fprintf(os.Stderr, "Warning: Output truncated at %d rows (use --limit to adjust)\n", limit)
            }
        }
        // ... rest unchanged
    },
}

func init() {
    readCmd.Flags().IntVarP(&readLimit, "limit", "l", 1000, "Maximum rows to read when no range specified (0 = unlimited)")
    rootCmd.AddCommand(readCmd)
}
```

#### Test File

**New**: `/home/fuabioo/Playground/excelize-mcp/internal/cli/read_test.go`

```go
package cli

import (
    "testing"
)

func TestReadCommandDefaultLimit(t *testing.T) {
    // Test that read without range applies default limit
    // This requires creating a test file with > 1000 rows
    // and verifying output is truncated
}

func TestReadCommandCustomLimit(t *testing.T) {
    // Test --limit flag is respected
}

func TestReadCommandRangeNoLimit(t *testing.T) {
    // Test that range-based reads are not limited
}
```

#### Acceptance Criteria

1. `xlq read large.xlsx` stops at 1000 rows by default
2. `xlq read large.xlsx --limit 50` stops at 50 rows
3. `xlq read large.xlsx --limit 0` reads all rows (explicit unlimited)
4. `xlq read file.xlsx A1:C10` is NOT limited (range specified)

---

## 5. Testing Strategy

### Pre-Fix Baseline

Run all existing tests to establish baseline:
```bash
cd /home/fuabioo/Playground/excelize-mcp
go test ./... -v 2>&1 | tee baseline_tests.log
go test -race ./internal/cli/... 2>&1 | tee baseline_race.log
go test -bench=. ./internal/xlsx/... 2>&1 | tee baseline_bench.log
```

### Per-Task Verification

Each task has specific tests. Run them before/after the fix:

| Task | Test Command |
|------|--------------|
| G1, G2, G3 | `go test -v -run Goroutine ./internal/xlsx/...` |
| M1 | `go test -bench=StreamTail -benchmem ./internal/xlsx/...` |
| S1 | `go test -v ./internal/mcp/...` (security tests) |
| R1 | `go test -race ./internal/cli/...` |
| C1 | `go test -v -run Context ./internal/mcp/...` |
| L1 | `go build ./...` (verify no broken imports) |
| U1 | `go test -v -run Read ./internal/cli/...` |

### Full Regression

After all fixes:
```bash
go test ./... -v
go test -race ./...
go test -bench=. -benchmem ./...
```

---

## 6. Rollout Plan

### Phase 1 Deployment (Critical Fixes)

1. Create feature branch: `fix/critical-issues`
2. Implement G1 -> G2, G3 -> M1 in sequence
3. Each commit should be atomic and independently testable
4. PR with full test results

### Phase 2 Deployment (High Fixes)

1. Continue on same branch or create `fix/high-issues`
2. S1, R1, C1, L1, U1 can be done in parallel
3. Final PR with complete test suite pass

### Release Checklist

- [ ] All existing tests pass
- [ ] All new tests pass
- [ ] Race detector clean: `go test -race ./...`
- [ ] Benchmarks show improvement (not regression)
- [ ] `go vet ./...` clean
- [ ] `golint ./...` clean
- [ ] README updated if CLI interface changed

---

## 7. Risk Assessment

| Risk | Mitigation |
|------|------------|
| Context addition breaks existing callers | Update all callers in same commit; use `context.Background()` as default in helpers |
| StreamTail rewrite introduces bugs | Comprehensive benchmark tests; keep old impl commented for reference |
| Path validation too restrictive | Allow configurable base paths via environment variable |
| LRU deletion removes needed future feature | Git history preserves code; can be restored if needed |

---

## 8. Appendix: File Reference

### Files to Modify

| File | Tasks | Changes |
|------|-------|---------|
| `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/stream.go` | G1, G2, M1 | Add context, rewrite StreamTail |
| `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/search.go` | G3 | Add context |
| `/home/fuabioo/Playground/excelize-mcp/internal/mcp/server.go` | S1, C1 | Add path validation, pass context |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/root.go` | R1 | Remove package-level formatFlag |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/head.go` | R1 | Remove package-level headN |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/tail.go` | R1 | Remove package-level tailN |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/read.go` | U1 | Add limit flag |

### Files to Create

| File | Task | Purpose |
|------|------|---------|
| `/home/fuabioo/Playground/excelize-mcp/internal/mcp/security.go` | S1 | Path validation utility |
| `/home/fuabioo/Playground/excelize-mcp/internal/mcp/context_test.go` | C1 | Context cancellation tests |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/read_test.go` | U1 | Read limit tests |

### Files to Delete (Conditional)

| File | Task | Condition |
|------|------|-----------|
| `/home/fuabioo/Playground/excelize-mcp/internal/cache/` | L1 | If deciding to remove dead code |

### Existing Test Files

| File | Tasks Verified |
|------|----------------|
| `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/goroutine_leak_test.go` | G1, G2, G3 |
| `/home/fuabioo/Playground/excelize-mcp/internal/xlsx/memory_bench_test.go` | M1 |
| `/home/fuabioo/Playground/excelize-mcp/internal/mcp/security_test.go` | S1 |
| `/home/fuabioo/Playground/excelize-mcp/internal/cli/race_test.go` | R1 |
