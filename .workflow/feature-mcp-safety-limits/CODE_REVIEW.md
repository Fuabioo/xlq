# CODE_REVIEW.md

**Generated By**: Reviewer Agent
**Generated At**: 2026-01-23
**Project Type**: Backend (Go)
**Skills Applied**: backend.md
**PR**: [#3 - feat(mcp): add safety limits to prevent context exhaustion](https://github.com/Fuabioo/xlq/pull/3)
**Files Reviewed**: 
- `internal/mcp/limits.go` (new)
- `internal/mcp/server.go` (modified)
- `internal/mcp/server_test.go` (modified)
- `internal/xlsx/stream.go` (modified)
- `internal/xlsx/stream_test.go` (modified)
- `.goreleaser.yaml` (modified)
- `README.md` (modified)

**Status**: Approved

## Summary

This PR implements essential safety limits for the MCP server to prevent AI agents from exhausting their context window when working with large Excel files. The implementation is clean, follows Go idioms, and includes comprehensive test coverage.

**Strengths:**
- Well-defined constants in a dedicated `limits.go` file for easy configuration
- Metadata structure (`rows_returned`, `truncated`, `limit`) enables intelligent client pagination
- Go-style error handling maintained throughout
- Explicit ranges bypass limits (correct design: user explicitly requested the range)
- Comprehensive test coverage for all limit scenarios

## Critical Issues (Must Fix)

None identified.

## Major Suggestions (Should Fix)

None identified.

## Minor Suggestions (Could Fix)

| File | Line | Issue | Suggestion |
|------|------|-------|------------|
| `internal/mcp/server.go` | L171 | Unused variable | `totalScanned` is assigned but only used in a blank identifier. Consider removing the variable entirely or using it in metadata. |
| `internal/mcp/limits.go` | - | Documentation | Consider adding a brief comment explaining the rationale for the specific limit values (e.g., "1000 rows typically fits within 100KB of JSON"). |
| `internal/mcp/server.go` | L225-226 | Magic number validation | The `n <= 0` check defaults to `DefaultHeadRows`, but the logic appears twice (head and tail). Consider extracting to a helper function `clampRows(n, default, max int) int`. |

## Verification Results

### 1. Limits are reasonable

| Operation | Default | Max | Verdict |
|-----------|---------|-----|---------|
| `read` (no range) | 1000 | 10000 | Reasonable - fits in typical context windows |
| `head` | 10 | 5000 | Good - safe defaults, generous max |
| `tail` | 10 | 5000 | Good - safe defaults, generous max |
| `search` | 100 | 1000 | Good - prevents overwhelming results |
| Output size | - | 5MB | Appropriate safety cap |

### 2. Metadata is returned properly

Verified in `jsonResultWithMetadata()`:
```go
result := map[string]interface{}{
    "data": data,
    "metadata": map[string]interface{}{
        "rows_returned": rowsReturned,
        "truncated":     truncated,
        "limit":         limit,
    },
}
```

Test coverage confirms structure: `TestJsonResultWithMetadata`

### 3. 5MB output limit is enforced

Verified in both `jsonResult()` and `jsonResultWithMetadata()`:
```go
if len(jsonData) > MaxOutputBytes {
    return mcp.NewToolResultError(fmt.Sprintf("Output too large (%d bytes, max %d bytes)..."))
}
```

Test coverage: `TestJsonResultOutputLimit`

### 4. No breaking changes to existing functionality

- CLI commands remain unchanged
- MCP tool signatures unchanged
- Only behavior change: unbounded operations now have limits
- Metadata addition is additive (clients ignoring it will still work)

**Note from IMPLEMENTATION.md**: This is technically a breaking change for clients expecting unlimited results, but the metadata allows clients to detect and adapt.

### 5. Tests cover the new limits

| Test | Coverage |
|------|----------|
| `TestLimitsConstants` | Verifies all constant values match requirements |
| `TestJsonResultOutputLimit` | Verifies 5MB cap enforcement |
| `TestJsonResultWithMetadata` | Validates metadata structure |
| `TestCollectRowsWithLimit` | Tests truncation behavior |
| `TestCollectRowsWithLimitNoTruncation` | Tests non-truncation case |
| `TestCollectRowsWithLimitError` | Tests error handling during collection |

## Positive Observations

1. **Clean separation of concerns**: Limits are defined in one place (`limits.go`), making future adjustments trivial.

2. **Streaming architecture preserved**: `CollectRowsWithLimit` maintains the streaming pattern while adding limits - no memory regressions.

3. **Good error messages**: The output size error includes both actual and max bytes, helpful for debugging.

4. **Updated tool descriptions**: MCP tool descriptions now mention limits upfront, setting correct expectations for AI agents.

5. **Defensive coding**: Invalid/negative values for `n` and `maxResults` are handled gracefully with defaults.

## Verdict

**APPROVE**

The implementation is solid, follows project conventions, and addresses a real problem (context exhaustion). The limits are reasonable for AI agent usage, and the metadata structure enables intelligent pagination patterns. Test coverage is comprehensive.
